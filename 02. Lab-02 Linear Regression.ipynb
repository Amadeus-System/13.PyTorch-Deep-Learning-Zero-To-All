{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02. Lab 02 Linear Regression.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNBOMdathA7LOpmUXey7iXY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"G5Fd2K0Ayvw8"},"source":["# Lab 2: Linear Regression\n","\n","We use elemental PyTorch to implement linear regression here. However, in most actual applications, abstractions such as `nn.Module` or `nn.Linear` are used.\n"]},{"cell_type":"markdown","metadata":{"id":"nY9DMFdSy3xR"},"source":["## Theoretical Overview\n","\n","$$H(x) = Wx + b$$\n","\n","$$cost(W, b) = \\frac{1}{m} \\sum^m_{i=1} \\left( H(x^{(i)}) - y^{(i)} \\right)^2$$\n","\n","* $H(x)$ : 주어진 $x$ 값에 대해 예측을 어떻게 할 것인가\n","\n","* $cost(W, b)$ : $H(x)$ 가 $y$ 를 얼마나 잘 예측했는가\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oaVzkHYry3zc"},"source":["## Imports\n"]},{"cell_type":"code","metadata":{"id":"9laWLEWCy31t","executionInfo":{"status":"ok","timestamp":1617605634393,"user_tz":-540,"elapsed":761,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m4NbJQX_y33n","executionInfo":{"status":"ok","timestamp":1617605651565,"user_tz":-540,"elapsed":739,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"4da5716e-73a1-4f6d-ec41-729092ee2b39"},"source":["# For reproducibility\n","torch.manual_seed(1)"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fac0b03a7d0>"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"g77D9GFVy35v"},"source":["## Data\n","\n","We will use fake data for this example.\n"]},{"cell_type":"code","metadata":{"id":"AqNKoLCwy372","executionInfo":{"status":"ok","timestamp":1617605743822,"user_tz":-540,"elapsed":736,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["x_train = torch.FloatTensor([[1],\n","                             [2],\n","                             [3]])\n","y_train = torch.FloatTensor([[1],\n","                             [2],\n","                             [3]])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5-6q2ziy393","executionInfo":{"status":"ok","timestamp":1617605745138,"user_tz":-540,"elapsed":943,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"8bc75d98-030d-46bb-be7f-916f41be66c8"},"source":["print(x_train)\n","print(x_train.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["tensor([[1.],\n","        [2.],\n","        [3.]])\n","torch.Size([3, 1])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"94mGKguhy3_n","executionInfo":{"status":"ok","timestamp":1617605745575,"user_tz":-540,"elapsed":901,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"70aeb748-c540-4e3c-cf48-da56aaceefa6"},"source":["print(y_train)\n","print(y_train.shape)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["tensor([[1.],\n","        [2.],\n","        [3.]])\n","torch.Size([3, 1])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hC4T9Wbhy4CN"},"source":["기본적으로 PyTorch는 N(Batch), C(Channel), H(Height), W(Width) 형태이다"]},{"cell_type":"markdown","metadata":{"id":"CWyXqb-V0ZC3"},"source":["## Weight Initialization\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xvDPtP-w0cOM","executionInfo":{"status":"ok","timestamp":1617605843747,"user_tz":-540,"elapsed":761,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"7dfa38eb-e198-4c4e-b0b7-7cf72eebfafe"},"source":["W = torch.zeros(1, requires_grad = True)\n","print(W)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["tensor([0.], requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tIXCth-60cQQ","executionInfo":{"status":"ok","timestamp":1617605859200,"user_tz":-540,"elapsed":913,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"c223b2eb-5783-4968-88ab-a85635e94a32"},"source":["b = torch.zeros(1, requires_grad = True)\n","print(b)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["tensor([0.], requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gjKnzxMQ0cSd"},"source":["## Hypothesis\n","\n","$$H(x) = Wx + b$$"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0iiyd4AQ0cUp","executionInfo":{"status":"ok","timestamp":1617605907468,"user_tz":-540,"elapsed":607,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"6b0e7ec2-5ccd-46bf-b565-78e3516481f4"},"source":["hypothesis = x_train * W + b\n","print(hypothesis)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["tensor([[0.],\n","        [0.],\n","        [0.]], grad_fn=<AddBackward0>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mzoplPsA0cW7"},"source":["## Cost\n","\n","$$cost(W, b) = \\frac{1}{m} \\sum^m_{i=1} \\left( H(x^{(i)}) - y^{(i)} \\right)^2$$\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZoHGEYnr0cap","executionInfo":{"status":"ok","timestamp":1617605949010,"user_tz":-540,"elapsed":725,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"9822808a-c860-4d67-fa6b-0a1aa8e3f9e4"},"source":["print(hypothesis)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["tensor([[0.],\n","        [0.],\n","        [0.]], grad_fn=<AddBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dvjqEnjm0ccx","executionInfo":{"status":"ok","timestamp":1617605956421,"user_tz":-540,"elapsed":765,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"175efa66-b6d1-461a-966e-3fb996ca926d"},"source":["print(y_train)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["tensor([[1.],\n","        [2.],\n","        [3.]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DRf08jOs1A_q","executionInfo":{"status":"ok","timestamp":1617605968714,"user_tz":-540,"elapsed":749,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"7a883afa-efa4-4465-9b19-a65c3efc9f09"},"source":["print(hypothesis - y_train)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["tensor([[-1.],\n","        [-2.],\n","        [-3.]], grad_fn=<SubBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JAMb7X3B1D-p","executionInfo":{"status":"ok","timestamp":1617605991128,"user_tz":-540,"elapsed":996,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"b81f4871-16ea-47b4-ecac-5acb1b910254"},"source":["print((hypothesis - y_train) ** 2)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["tensor([[1.],\n","        [4.],\n","        [9.]], grad_fn=<PowBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FDfngRzd1JbU","executionInfo":{"status":"ok","timestamp":1617606014343,"user_tz":-540,"elapsed":733,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"c6f72747-bf9e-4ed5-ed05-3cc56f872edb"},"source":["cost = torch.mean((hypothesis - y_train) ** 2)\n","print(cost)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["tensor(4.6667, grad_fn=<MeanBackward0>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vm3wwZpO1PDX"},"source":["## Gradient Descent\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9KukV0oS1RcW","executionInfo":{"status":"ok","timestamp":1617606065101,"user_tz":-540,"elapsed":769,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"dbba18bf-edc8-4d76-ac43-329ca2041017"},"source":["optimizer = optim.SGD(params = [W, b], lr = 0.01)\n","print(optimizer)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["SGD (\n","Parameter Group 0\n","    dampening: 0\n","    lr: 0.01\n","    momentum: 0\n","    nesterov: False\n","    weight_decay: 0\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bKak-Yss1Reb","executionInfo":{"status":"ok","timestamp":1617606087050,"user_tz":-540,"elapsed":738,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["optimizer.zero_grad() # optimizer의 gradient 초기화\n","cost.backward() # 계산 그래프 곳곳의 gradient 계산한다.\n","optimizer.step() # 1번의 최적화(optimization) step을 실행한다. "],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"heBCnFqC1Rie","executionInfo":{"status":"ok","timestamp":1617606093965,"user_tz":-540,"elapsed":493,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"3ba91d57-1d30-489a-f250-7395d3fa398c"},"source":["print(W)\n","print(b)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["tensor([0.0933], requires_grad=True)\n","tensor([0.0400], requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QZ8O5sT41RlJ"},"source":["Let's check if the hypothesis is now better.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0o1H5sKm1Rm5","executionInfo":{"status":"ok","timestamp":1617606134857,"user_tz":-540,"elapsed":830,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"c7f972f8-1702-4fe5-ab21-0b795dd26ae8"},"source":["hypothesis = x_train * W + b # 이제 학습된 가중치로 다시 가설을 확인한다.\n","print(hypothesis)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["tensor([[0.1333],\n","        [0.2267],\n","        [0.3200]], grad_fn=<AddBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xwjmu9w-1Ro1","executionInfo":{"status":"ok","timestamp":1617606167098,"user_tz":-540,"elapsed":760,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"61245022-75a6-4f2e-febf-73806df19e07"},"source":["cost = torch.mean((hypothesis - y_train) ** 2)\n","print(cost) # 학습 전의 cost = 4.6667에 비해 cost가 감소하였다."],"execution_count":22,"outputs":[{"output_type":"stream","text":["tensor(3.6927, grad_fn=<MeanBackward0>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u_zsCgix1Rq5"},"source":["## Training with Full Code\n","\n","In reality, we will be training on the dataset for multiple epochs. This can be done simply with loops.\n","\n","(실제로 우리는 여러 에포크 동안 데이터셋에 대해 훈련할 것이다. 이는 루프(loop)로 간단히 실행될 수 있다.)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"auBMk8DZ1RtQ","executionInfo":{"status":"ok","timestamp":1617606556850,"user_tz":-540,"elapsed":900,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"83e2730b-21ee-49a4-e852-2021bf6dc556"},"source":["# 데이터\n","x_train = torch.FloatTensor([[1],\n","                             [2],\n","                             [3]])\n","y_train = torch.FloatTensor([[1],\n","                             [2],\n","                             [3]])\n","# 모델 초기화\n","W = torch.zeros(1, requires_grad = True)\n","b = torch.zeros(1, requires_grad = True)\n","\n","# optimizer 설정\n","optimizer = optim.SGD([W, b], lr = 0.01)\n","\n","nb_epochs = 1000\n","for epoch in range(nb_epochs + 1):\n","\n","    # H(x) 계산\n","    hypothesis = x_train * W + b\n","\n","    # cost 계산\n","    cost = torch.mean((hypothesis - y_train) ** 2)\n","\n","    # cost로 H(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    # 100번마다 로그 출력\n","    if epoch % 100 == 0:\n","        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, W.item(), b.item(), cost.item()\n","        ))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Epoch    0/1000 W: 0.093, b: 0.040 Cost: 4.666667\n","Epoch  100/1000 W: 0.873, b: 0.289 Cost: 0.012043\n","Epoch  200/1000 W: 0.900, b: 0.227 Cost: 0.007442\n","Epoch  300/1000 W: 0.921, b: 0.179 Cost: 0.004598\n","Epoch  400/1000 W: 0.938, b: 0.140 Cost: 0.002842\n","Epoch  500/1000 W: 0.951, b: 0.110 Cost: 0.001756\n","Epoch  600/1000 W: 0.962, b: 0.087 Cost: 0.001085\n","Epoch  700/1000 W: 0.970, b: 0.068 Cost: 0.000670\n","Epoch  800/1000 W: 0.976, b: 0.054 Cost: 0.000414\n","Epoch  900/1000 W: 0.981, b: 0.042 Cost: 0.000256\n","Epoch 1000/1000 W: 0.985, b: 0.033 Cost: 0.000158\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xfPpb2-31RvI"},"source":["## High-level Implementation with `nn.Module`\n","\n","Remember that we had this fake data.\n"]},{"cell_type":"code","metadata":{"id":"GutNYpaT3dPk","executionInfo":{"status":"ok","timestamp":1617606645616,"user_tz":-540,"elapsed":735,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["x_train = torch.FloatTensor([[1],\n","                             [2],\n","                             [3]])\n","y_train = torch.FloatTensor([[1],\n","                             [2],\n","                             [3]])"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AlxxLs313pRs"},"source":["이제 linear regression 모델을 만들면 되는데, 기본적으로 PyTorch의 모든 모델은 제공되는 `nn.Module`을 inherit(상속)하여 만들게 된다.\n"]},{"cell_type":"code","metadata":{"id":"2Qt4LHQN30Ox","executionInfo":{"status":"ok","timestamp":1617606737997,"user_tz":-540,"elapsed":812,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["class LinearRegressionModel(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.linear = nn.Linear(1, 1)\n","\n","    def forward(self, x):\n","        return self.linear(x)"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MmV-AXj_32dt"},"source":["모델의 `__init__`에서는 사용할 레이어들을 정의하게 된다. 여기서 우리는 linear regression 모델을 만들기 때문에, `nn.Linear`을 이용할 것이다. 그리고 `forward`에서는 이 모델이 어떻게 입력값에서 출력값을 계산하는지 알려준다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qP8yuW1Z32he","executionInfo":{"status":"ok","timestamp":1617606820191,"user_tz":-540,"elapsed":753,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"92ad3e3b-256a-4fbd-b5d7-c30ac855b51c"},"source":["model = LinearRegressionModel()\n","print(model)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["LinearRegressionModel(\n","  (linear): Linear(in_features=1, out_features=1, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1UfH80kc32j2"},"source":["## Hypothesis\n","\n","이제 모델을 생성해서 예측값 $H(x)$를 구해보자.\n"]},{"cell_type":"code","metadata":{"id":"c0Rg-Ua632lt","executionInfo":{"status":"ok","timestamp":1617606870244,"user_tz":-540,"elapsed":713,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["hypothesis = model(x_train)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-W0YsWv32oZ","executionInfo":{"status":"ok","timestamp":1617606875030,"user_tz":-540,"elapsed":738,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"e74523a6-fd47-4958-856e-afcb7abeb2c0"},"source":["print(hypothesis)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["tensor([[0.0739],\n","        [0.5891],\n","        [1.1044]], grad_fn=<AddmmBackward>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3S1OGU2E32p4"},"source":["## Cost\n","\n","이제 mean squared error (MSE)로 cost를 구해보자. MSE 역시 PyTorch에서 기본적으로 제공한다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ANA9YqQr32sF","executionInfo":{"status":"ok","timestamp":1617606925719,"user_tz":-540,"elapsed":784,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"74ec55eb-5678-47b9-992a-0dfb51f9701a"},"source":["print(hypothesis)\n","print(y_train)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["tensor([[0.0739],\n","        [0.5891],\n","        [1.1044]], grad_fn=<AddmmBackward>)\n","tensor([[1.],\n","        [2.],\n","        [3.]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UkfG2RS532uL","executionInfo":{"status":"ok","timestamp":1617606953697,"user_tz":-540,"elapsed":922,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["cost = F.mse_loss(hypothesis, y_train)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tgb2qACo32yA","executionInfo":{"status":"ok","timestamp":1617606956202,"user_tz":-540,"elapsed":812,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"760dec1b-39b7-4733-aaa4-a86292ac435a"},"source":["print(cost)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["tensor(2.1471, grad_fn=<MseLossBackward>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5xYEtXd0320K"},"source":["## Gradient Descent\n","\n","마지막으로 주어진 cost를 이용해 $H(x)$의 $W, b$를 바꾸어서 cost를 줄여본다. 이때 PyTorch의 `torch.optim`에 있는 `optimizer`들 중 하나를 사용할 수 있다.\n"]},{"cell_type":"code","metadata":{"id":"cQrNMYFZ322D","executionInfo":{"status":"ok","timestamp":1617607056970,"user_tz":-540,"elapsed":727,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["optimizer = optim.SGD(model.parameters(), lr = 0.01)\n"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"FifNU8oe5NtG","executionInfo":{"status":"ok","timestamp":1617607070781,"user_tz":-540,"elapsed":728,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["optimizer.zero_grad()\n","cost.backward()\n","optimizer.step()"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UdFBuGVA5RFB"},"source":["## Training with Full Code\n","\n","이제 Linear Regression 코드를 이해했으니, 실제로 코드를 돌려 fitting 시켜보겠다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oF6-Zzvu5YSl","executionInfo":{"status":"ok","timestamp":1617607325430,"user_tz":-540,"elapsed":1017,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"4ca55e07-6bc6-46b0-df78-e385db12ecb3"},"source":["# 데이터\n","x_train = torch.FloatTensor([[1],\n","                             [2],\n","                             [3]])\n","y_train = torch.FloatTensor([[1],\n","                             [2],\n","                             [3]])\n","# 모델 초기화\n","model = LinearRegressionModel()\n","\n","# optimizer 설정\n","optimizer = optim.SGD(model.parameters(), lr = 0.01)\n","\n","nb_epochs = 1000\n","for epoch in range(nb_epochs + 1):\n","\n","    # H(x) 계산\n","    prediction = model(x_train)\n","\n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train)\n","\n","    # cost로 H(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    # 100번마다 로그 출력\n","    if epoch % 100 == 0:\n","        params = list(model.parameters())\n","        W = params[0].item()\n","        b = params[1].item()\n","        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, W, b, cost.item()\n","        ))"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Epoch    0/1000 W: -0.101, b: 0.508 Cost: 4.630286\n","Epoch  100/1000 W: 0.713, b: 0.653 Cost: 0.061555\n","Epoch  200/1000 W: 0.774, b: 0.514 Cost: 0.038037\n","Epoch  300/1000 W: 0.822, b: 0.404 Cost: 0.023505\n","Epoch  400/1000 W: 0.860, b: 0.317 Cost: 0.014525\n","Epoch  500/1000 W: 0.890, b: 0.250 Cost: 0.008975\n","Epoch  600/1000 W: 0.914, b: 0.196 Cost: 0.005546\n","Epoch  700/1000 W: 0.932, b: 0.154 Cost: 0.003427\n","Epoch  800/1000 W: 0.947, b: 0.121 Cost: 0.002118\n","Epoch  900/1000 W: 0.958, b: 0.095 Cost: 0.001309\n","Epoch 1000/1000 W: 0.967, b: 0.075 Cost: 0.000809\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aNp950Bi5iqf"},"source":["점점 $H(x)$의 $W$와 $b$를 조정해서 cost가 줄어드는 것을 볼 수 있다.\n","\n"]}]}